{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ex 1\n",
    "\n",
    "Starting from the dictionary in which you saved the MEN dataset, create a .txt file and try to replicate the original one. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"../data/MEN/MEN_dataset_natural_form_full\", \"r\", encoding=\"utf8\")\n",
    "men = file.readlines()\n",
    "\n",
    "d = {}\n",
    "for el in men:\n",
    "    l = el.strip(\"\\n\").split()\n",
    "    d[l[0]] = (l[1], float(l[2]))\n",
    "    \n",
    "def save_men(path, data):\n",
    "    file = open(path, \"w\", encoding=\"utf8\")\n",
    "    for el in data.items():\n",
    "        line = el[0] + \" \" +  el[1][0] + \" \" + str(el[1][1]) + \"\\n\"\n",
    "        file.write(line)\n",
    "    file.close()\n",
    "    \n",
    "save_men(\"my_text.txt\", d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ex 2\n",
    "\n",
    "Let's do something similar changing the dataset. The new dataset, netflix_shows.csv, is avaiable in the \"Data\" folder. Every line of the file contains datils about a different Netflix TV Series. Data are <b>semicolon-separeted</b>, as shown in the example below.\n",
    "\n",
    "<p style=\"text-align:center\">Stranger Things;Science Fiction Horror;\"July 15, 2016\";3;25</p>\n",
    "\n",
    "corresponding to: \n",
    "\n",
    "<p style=\"text-align:center\">Title;Genre;Premiere;No_of_Seasons;No_of_Episodes</p>\n",
    "\n",
    "Create a function that takes the path to the dataset as argument and returns a dictionary whose <b>keys</b> are the titles of the shows and <b>values</b> consists in a list of the related informations. Convert <em>No_of_Seasons</em>,<em>No_of_Episodes</em> data into integers before storing them in the dictionary. The final result sould look like this: \n",
    "\n",
    "```\n",
    "{\n",
    "  \"Stranger Things\" : ['Science Fiction Horror','July 15, 2016','3','25'],\n",
    "  ...\n",
    "}\n",
    "```\n",
    "\n",
    "Then, anwers to the following questions:\n",
    "- Create a list of all the titles. How many TV series are there in the dataset?  \n",
    "- Which TV series start with the letter \"B\"? Store them in a list (try to use list comprehension). \n",
    "- Which TV series end with the letter \"s\"? Store them in a list (try to use list comprehension).\n",
    "- Which TV series have more than 50 episodes? Store them in a list (try to use list comprehension). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def netflix_dataset(path):\n",
    "    file = open(path, \"r\", encoding=\"utf-8-sig\")\n",
    "    data = file.readlines()\n",
    "    \n",
    "    d = {}\n",
    "    for el in data: \n",
    "        show_info = el.strip(\"\\n\").split(\";\")\n",
    "        d[show_info[0]] = [show_info[1],show_info[2],int(show_info[3]),int(show_info[4])]\n",
    "    file.close()\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = netflix_dataset(\"../data/netflix_shows.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of all the titles. How many TV series are there in the dataset?\n",
    "titles = list(dataset.keys())\n",
    "print(f\"There are {len(titles)} TV series in the dataset.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which TV series start with the letter \"b\"? Store them in a list.\n",
    "b_titles = [el for el in titles if el.startswith(\"B\")]\n",
    "b_titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which TV series start with the letter \"b\"? Store them in a list.\n",
    "b_titles = [el for el in titles if el.endswith(\"s\")]\n",
    "b_titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which TV series have more than 30 episodes? Store them in a list.\n",
    "long_shows = [show[0] for show in dataset.items() if show[1][3] > 30]\n",
    "long_shows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ex 3\n",
    "\n",
    "Create a function that takes three arguments: \n",
    "- a path to a text file\n",
    "- a default argument <i>removestopwords</i> set to False\n",
    "- a default argument <i>writetofile</i> set to False\n",
    "\n",
    "Stop words are basically a set of commonly used words in any language, not just English. Sometimes it is better to remove them while preprocessing a text. You can find a list of English stop words in the file <i>stop_words_english.txt</i>. Starting from this file, create a list of stop words. \n",
    "\n",
    "The function must tokenize the input text and return the sorted dictionary of their frequencies. If <em>removestopwords</em> is True, remove stopwords from the tokens list and then return the sorted dictionary of frequencies. If <em>writetofile</em> is True, save the list of tokens and related frequencies (one per line and separated by a space) in a file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import string\n",
    "\n",
    "stopwords = open(\"../data/stop_words_english.txt\", encoding=\"utf-8\").read().split(\"\\n\")\n",
    "\n",
    "def freq(tokens):\n",
    "    d = {}\n",
    "    for tok in tokens: \n",
    "        if tok in d:\n",
    "            d[tok] += 1\n",
    "        else:\n",
    "            d[tok] = 1\n",
    "    return sorted(d.items(), key=lambda x:x[1], reverse=True)\n",
    "\n",
    "\n",
    "\n",
    "def tokenizer(path, removestopwords=False, writetofile=False):\n",
    "    file = open(path, \"r\", encoding=\"utf-8-sig\")\n",
    "    text = file.read()\n",
    "    file.close()\n",
    "    \n",
    "    for char in text:\n",
    "        if char in string.punctuation + \"’“”\":\n",
    "            text = text.replace(char,\"\")\n",
    "\n",
    "    tokens = nltk.word_tokenize(text.lower())\n",
    "    \n",
    "    if removestopwords == True:\n",
    "        tokens = [tok for tok in tokens if tok not in stopwords]\n",
    "    \n",
    "    d = freq(tokens)\n",
    "    \n",
    "    if writetofile == True:\n",
    "        file = open(\"tokens_freq.txt\", \"w\", encoding=\"utf-8\")\n",
    "        for el in d:\n",
    "            file.write(el[0] + \" \" + str(el[1]) + \"\\n\")\n",
    "        file.close()\n",
    "    return d\n",
    "\n",
    "\n",
    "tokenizer(\"../data/mystery.txt\", removestopwords=True, writetofile=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ex 4\n",
    "\n",
    "It is time to work with numbers. Two basic operations that you will find in your career of Compuational Linguists are <b>mean</b> and <b>standard deviation</b>. \n",
    "\n",
    "The arithmetic mean (or simply mean) of a list of numbers, is the sum of all of the numbers divided by the number of numbers. Similarly, the mean of a sample $x_1,x_2,\\ldots ,x_n$, usually denoted by $\\bar x$, is the sum of the sampled values divided by the number of items in the sample. \n",
    "\n",
    "$\\bar x = \\frac{1}{n}(\\sum \\limits _{i=1} ^{n}x_i) = \\frac{x_1 + x_2 + \\dots + x_n}{n}$\n",
    "    \n",
    "In statistics, the standard deviation is a measure of the amount of variation or dispersion of a set of values. A low standard deviation indicates that the values tend to be close to the mean (also called the expected value) of the set, while a high standard deviation indicates that the values are spread out over a wider range.\n",
    " \n",
    "The formula for standard deviation is defined as follows:\n",
    "\n",
    "$\\sigma = \\sqrt{\\frac{1}{N}\\sum\\limits _{i=1}^{N}(x_i - \\bar x)^2}$\n",
    "    \n",
    "where $x_1,x_2,\\ldots ,x_n$ are the observed values of the sample items, and $\\bar x$ is the mean value of these observations, while the denominator N stands for the size of the sample.\n",
    "    \n",
    "Write two functions that take as argument the list of numbers in <i>numbers.txt</i> and return one the mean and the standard deviation. Try to optimize the code, avoiding code repetitions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "numbers = open(\"numbers.txt\", \"r\", encoding=\"utf-8\").read().split(\",\")\n",
    "print(type(numbers[0]))\n",
    "\n",
    "# converting str to int\n",
    "numbers = [int(num) for num in numbers]\n",
    "print(type(numbers[0]))\n",
    "\n",
    "def mean(sample):\n",
    "    x = sum(numbers) / len(numbers)\n",
    "    return x\n",
    "\n",
    "def stdev(sample):\n",
    "    m = mean(sample)\n",
    "    differences = [(m - x)**2 for x in sample]\n",
    "    var = sum(differences) / len(sample)\n",
    "    return math.sqrt(var)\n",
    "        \n",
    "print(f\"Mean is: {mean(numbers)}\")\n",
    "print(f\"Standard Deviation is: {stdev(numbers)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
